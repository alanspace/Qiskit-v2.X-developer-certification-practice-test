{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qiskit Certification Practice Test\n",
    "\n",
    "This notebook provides an interactive practice environment for the Qiskit Associate Developer certification. \n",
    "\n",
    "## How to Use\n",
    "1. Click \"Run All\" to start the practice session\n",
    "2. When prompted for student history:\n",
    "   - Type `None` (without quotes) to start fresh\n",
    "   - Or provide a path to load previous history\n",
    "3. Use the menu to:\n",
    "   - Take practice tests (option 1)\n",
    "   - Save your progress (option 2)\n",
    "   - View your stats (option 4)\n",
    "   - Quit (option 3)\n",
    "\n",
    "## During Practice Tests\n",
    "- Answer questions by typing A, B, C, or D\n",
    "- Get immediate feedback and explanations\n",
    "- Track your progress across topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap done — now run the cell that defines core functions if present.\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap guard for quick testing (paste as new first cell)\n",
    "import sys, pickle, time, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Local paths (adjust if needed)\n",
    "BLANK_STUDENT_HISTORY_FILE = \"necessary_files/student_history.pkl\"\n",
    "STUDENT_HISTORY_SAVE_FOLDER = \"necessary_files/\"\n",
    "TASK_BY_SECTION_DICT_FILE = \"necessary_files/task_by_section_dict.pkl\"\n",
    "PERCENT_BY_TASK_DICT_FILE = \"necessary_files/percentage_by_task_dict.pkl\"\n",
    "QUESTION_BANK_DF_FILE = \"necessary_files/question_df.pkl\"\n",
    "\n",
    "# Minimal safe loader if not yet defined\n",
    "def _safe_load_pickle(path_str):\n",
    "    p = Path(path_str)\n",
    "    if not p.exists(): \n",
    "        raise FileNotFoundError(path_str)\n",
    "    with open(p,\"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# If the notebook already defines safe_load_pickle/generate_test/load_student_history,\n",
    "# we won't override them. This just ensures the names exist for test cells.\n",
    "if \"safe_load_pickle\" not in globals():\n",
    "    safe_load_pickle = lambda p, **kw: _safe_load_pickle(p)\n",
    "if \"load_student_history\" not in globals():\n",
    "    def load_student_history(fp):\n",
    "        try:\n",
    "            with open(fp,\"rb\") as f:\n",
    "                sh = pickle.load(f)\n",
    "            # best-effort normalization\n",
    "            for c in [\"Number_attempts\",\"Number_correct\"]:\n",
    "                if c not in sh.columns:\n",
    "                    sh[c] = 0\n",
    "            if \"score\" not in sh.columns:\n",
    "                sh[\"score\"] = (sh[\"Number_correct\"].astype(float) + 1.0) / (sh[\"Number_attempts\"].astype(float) * 1.001 + 0.001)\n",
    "            return sh, True\n",
    "        except Exception as e:\n",
    "            print(\"load_student_history bootstrap error:\", e)\n",
    "            return None, False\n",
    "if \"generate_test\" not in globals():\n",
    "    def generate_test(*args, **kwargs):\n",
    "        raise RuntimeError(\"generate_test not defined yet — run the main function-definition cell first\")\n",
    "print(\"Bootstrap done — now run the cell that defines core functions if present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_STUDENT_HISTORY_FILE = \"necessary_files/student_history.pkl\"\n",
    "STUDENT_HISTORY_SAVE_FOLDER = \"necessary_files/\" # must be writable\n",
    "TASK_BY_SECTION_DICT_FILE = \"necessary_files/task_by_section_dict.pkl\"\n",
    "PERCENT_BY_TASK_DICT_FILE = \"necessary_files/percentage_by_task_dict.pkl\"\n",
    "QUESTION_BANK_DF_FILE = \"necessary_files/question_df.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Helper functions and prompts\n",
    "# ---------------------------\n",
    "\n",
    "def prompt_choice(prompt, valid_choices, to_lower=True):\n",
    "    \"\"\"Prompt until user enters a valid string choice from valid_choices.\"\"\"\n",
    "    valid = {str(v).lower() if to_lower else str(v): v for v in valid_choices}\n",
    "    while True:\n",
    "        val = input(prompt).strip()\n",
    "        key = val.lower() if to_lower else val\n",
    "        if key in valid:\n",
    "            return valid[key]\n",
    "        print(f\"Invalid selection. Valid options: {sorted(valid_choices)}\")\n",
    "\n",
    "def prompt_int(prompt, min_val=None, max_val=None):\n",
    "    \"\"\"Prompt until user enters an int within optional [min_val, max_val].\"\"\"\n",
    "    while True:\n",
    "        val = input(prompt).strip()\n",
    "        try:\n",
    "            n = int(val)\n",
    "        except ValueError:\n",
    "            print(\"Please enter a whole number.\")\n",
    "            continue\n",
    "        if min_val is not None and n < min_val:\n",
    "            print(f\"Enter a number >= {min_val}.\")\n",
    "            continue\n",
    "        if max_val is not None and n > max_val:\n",
    "            print(f\"Enter a number <= {max_val}.\")\n",
    "            continue\n",
    "        return n\n",
    "\n",
    "def prompt_yes_no(prompt):\n",
    "    \"\"\"Return True/False from 1/0 (or y/n).\"\"\"\n",
    "    while True:\n",
    "        val = input(prompt + \" \").strip().lower()\n",
    "        if val in {\"1\", \"y\", \"yes\"}:\n",
    "            return True\n",
    "        if val in {\"0\", \"n\", \"no\"}:\n",
    "            return False\n",
    "        print(\"Please enter 1/0 or y/n.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Safe loaders and utilities\n",
    "# ---------------------------\n",
    "\n",
    "def safe_load_pickle(path_str, required=True, expected_type=None, var_name=\"object\"):\n",
    "    p = Path(path_str)\n",
    "    if not p.exists():\n",
    "        msg = f\"[ERROR] Missing file: {p}\"\n",
    "        if required:\n",
    "            raise FileNotFoundError(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "            return None\n",
    "    if p.stat().st_size == 0:\n",
    "        msg = f\"[ERROR] Empty file: {p}\"\n",
    "        if required:\n",
    "            raise ValueError(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "            return None\n",
    "    with open(p, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    if expected_type is not None and not isinstance(obj, expected_type):\n",
    "        msg = f\"[ERROR] {var_name} should be {expected_type}, got {type(obj)} from {p}\"\n",
    "        if required:\n",
    "            raise TypeError(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "            return None\n",
    "    return obj\n",
    "\n",
    "# Load data files and apply development mode sampling if needed\n",
    "try:\n",
    "    file_path = TASK_BY_SECTION_DICT_FILE\n",
    "    task_by_section_dict = safe_load_pickle(file_path,\n",
    "                                            required=True, expected_type=dict,\n",
    "                                            var_name=\"task_by_section_dict\")\n",
    "    file_path = PERCENT_BY_TASK_DICT_FILE\n",
    "    percentage_by_task_dict = safe_load_pickle(file_path,\n",
    "                                               required=True, expected_type=dict,\n",
    "                                               var_name=\"percentage_by_task_dict\")\n",
    "    file_path = QUESTION_BANK_DF_FILE\n",
    "    question_df = safe_load_pickle(file_path,required=True, expected_type=pd.DataFrame,var_name=\"question_df\")\n",
    "    \n",
    "    # Clean and sample the question bank\n",
    "    question_df = question_df[question_df[\"Question\"].astype(str).str.strip().str.lower() != 'question']\n",
    "    \n",
    "    # Development mode: use a smaller reproducible subset\n",
    "    DEVELOPMENT_MODE = False  # Set True for faster iteration with sample dataset\n",
    "    if DEVELOPMENT_MODE:\n",
    "        n_dev = min(300, len(question_df))\n",
    "        question_df = question_df.sample(n=n_dev, random_state=42).reset_index(drop=True)\n",
    "        print(\"DEVELOPMENT_MODE: using\", len(question_df), \"rows\")\n",
    "    else:\n",
    "        # Production: full randomized dataset\n",
    "        question_df = question_df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "# Basic sanity checks\n",
    "required_cols = {\"Question\", \"Section\", \"Task\"}\n",
    "missing = required_cols - set(question_df.columns)\n",
    "if missing:\n",
    "    print(f\"[ERROR] question_df missing required columns: {missing}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if len(question_df) == 0:\n",
    "    print(\"[ERROR] question_df is empty; cannot proceed.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Helper functions for practice session\n",
    "def save_student_history(student_history):\n",
    "    root = STUDENT_HISTORY_SAVE_FOLDER\n",
    "    # Make the filename FS-friendly\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = root + f\"student_history_{ts}.pkl\"\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(student_history, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Student History saved to:\", save_path)\n",
    "\n",
    "def update_scores(student_history):\n",
    "    \"\"\"Vectorized 'score' = (Number_correct + 1) / (Number_attempts*(1+eps) + eps).\"\"\"\n",
    "    epsilon = 1e-3\n",
    "    attempt_penalty = 1 + epsilon\n",
    "    num = student_history[\"Number_correct\"].astype(float) + 1.0\n",
    "    den = student_history[\"Number_attempts\"].astype(float) * attempt_penalty + epsilon\n",
    "    student_history[\"score\"] = num / den\n",
    "\n",
    "def load_student_history(file_path):\n",
    "    \"\"\"Returns (student_history, resolved: bool). If 'None', create a new empty structure.\"\"\"\n",
    "    if file_path in [\"None\", \"none\", \"NONE\"]:\n",
    "        print(\"Creating new student history (empty).\")\n",
    "        file_path = BLANK_STUDENT_HISTORY_FILE\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            student_history = pickle.load(f)\n",
    "        print(\"Loaded Student History\")\n",
    "        # Ensure required columns exist and normalize\n",
    "        for c in [\"Number_attempts\",\"Number_correct\"]:\n",
    "            if c not in student_history.columns:\n",
    "                student_history[c] = 0\n",
    "        if \"score\" not in student_history.columns:\n",
    "            update_scores(student_history)\n",
    "        return student_history, True\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to load student history: {e}\")\n",
    "        return None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Stats placeholder\n",
    "# ---------------------------\n",
    "\n",
    "def print_stats(student_history: pd.DataFrame):\n",
    "    import pandas as pd\n",
    "\n",
    "    if not isinstance(student_history, pd.DataFrame):\n",
    "        print(\"[ERROR] student_history is not a DataFrame.\")\n",
    "        return\n",
    "\n",
    "    needed = {\"Question\", \"Section\", \"Task\", \"Number_attempts\", \"Number_correct\"}\n",
    "    miss = needed - set(student_history.columns)\n",
    "    if miss:\n",
    "        print(f\"[ERROR] student_history missing columns: {miss}\")\n",
    "        return\n",
    "\n",
    "    # Overall metrics\n",
    "    total_questions = len(student_history)\n",
    "    ever_attempted = int((student_history[\"Number_attempts\"] > 0).sum())\n",
    "    total_attempts = int(student_history[\"Number_attempts\"].sum())\n",
    "    total_correct  = int(student_history[\"Number_correct\"].sum())\n",
    "    overall_acc = (100.0 * total_correct / total_attempts) if total_attempts > 0 else 0.0\n",
    "\n",
    "    print(\"=== Student History — Overall ===\")\n",
    "    print(f\"Questions ever attempted : {ever_attempted} / {total_questions}\")\n",
    "    print(f\"Total attempts           : {total_attempts}\")\n",
    "    print(f\"Total correct            : {total_correct}\")\n",
    "    print(f\"Overall accuracy         : {overall_acc:.2f}%\")\n",
    "\n",
    "    # By-section aggregation\n",
    "    grp = student_history.groupby(\"Section\", dropna=False, as_index=False).agg(\n",
    "        total_questions=(\"Question\", \"count\"),\n",
    "        ever_attempted=(\"Number_attempts\", lambda s: int((s > 0).sum())),\n",
    "        attempts=(\"Number_attempts\", \"sum\"),\n",
    "        correct=(\"Number_correct\", \"sum\"),\n",
    "    )\n",
    "    # Section accuracy = sum(correct)/sum(attempts) for that section\n",
    "    grp[\"accuracy_pct\"] = grp.apply(\n",
    "        lambda r: (100.0 * r[\"correct\"] / r[\"attempts\"]) if r[\"attempts\"] > 0 else 0.0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    if not grp.empty:\n",
    "        print(\"\\n=== By Section ===\")\n",
    "        # Pretty print a compact table\n",
    "        cols = [\"Section\", \"ever_attempted\", \"total_questions\", \"attempts\", \"correct\", \"accuracy_pct\"]\n",
    "        # Align and format\n",
    "        for _, r in grp[cols].sort_values(\"Section\").iterrows():\n",
    "            print(f\"- {r['Section']}: \",\n",
    "                f\"attempted {int(r['ever_attempted'])}/{int(r['total_questions'])} | \",\n",
    "                f\"attempts {int(r['attempts'])} | correct {int(r['correct'])} | \",\n",
    "                f\"acc {r['accuracy_pct']:.2f}%\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Menu and parameter prompts\n",
    "# ---------------------------\n",
    "\n",
    "TOPIC_MAP = {\n",
    "    \"1\": 'Section 1: Perform quantum operations',\n",
    "    \"2\": 'Section 2: Visualize quantum circuits, measurements, and states',\n",
    "    \"3\": 'Section 3: Create quantum circuits',\n",
    "    \"4\": 'Section 4: Run quantum circuits',\n",
    "    \"5\": 'Section 5: Use the sampler primitive',\n",
    "    \"6\": 'Section 6: Use the estimator primitive',\n",
    "    \"7\": 'Section 7: Retrieve and analyze the results of quantum circuits',\n",
    "    \"8\": 'Section 8: Operate with OpenQASM'\n",
    "}\n",
    "\n",
    "def main_menu(student_history: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns (quit_flag: bool, practice_flag: bool)\n",
    "    \"\"\"\n",
    "    print(\"\"\"\n",
    "What would you like to do (type only the number)\n",
    "    1 Take a practice test\n",
    "    2 Save student history\n",
    "    3 Quit\n",
    "    4 View stats on my student history\n",
    "\"\"\")\n",
    "    choice = prompt_choice(\"Enter choice: \", {\"1\", \"2\", \"3\", \"4\"})\n",
    "    if choice == \"1\":\n",
    "        return (False, True)\n",
    "    elif choice == \"2\":\n",
    "        save_student_history(student_history)\n",
    "        return (False, False)\n",
    "    elif choice == \"3\":\n",
    "        return (True, False)\n",
    "    else:  # \"4\"\n",
    "        print_stats(student_history)\n",
    "        return (False, False)\n",
    "\n",
    "def get_practice_params(question_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      full_test: bool  (True = exam over all topics; False = select topics)\n",
    "      number_of_questions: int\n",
    "      timed: bool\n",
    "      adaptive_mode: int  (0, 1, or 2)\n",
    "      quit_requested: bool\n",
    "      topic_key: str or None (if not selecting by topic)\n",
    "    \"\"\"\n",
    "    total_questions = len(question_df)\n",
    "    if total_questions <= 0:\n",
    "        print(\"[ERROR] No questions available.\")\n",
    "        return True, 0, False, 2, True, None\n",
    "\n",
    "    print(\"\"\"Type '0' for an exam over all topics (proportions roughly match the test).\n",
    "Type '1' to select a topic.\"\"\")\n",
    "    ft_choice = prompt_choice(\"Enter 0 or 1: \", {\"0\", \"1\"})\n",
    "    full_test = (ft_choice == \"0\")\n",
    "\n",
    "    # Number of questions (bound to available)\n",
    "    number_of_questions = prompt_int(\n",
    "        f\"How many questions would you like? (1..{total_questions}) \",\n",
    "        min_val=1,\n",
    "        max_val=total_questions)\n",
    "\n",
    "    # Timing suggestion\n",
    "    suggested_seconds = int(round(79.411 * number_of_questions))\n",
    "    timed = prompt_yes_no(\n",
    "        f\"Do you want your test timed? Suggested {suggested_seconds} seconds for {number_of_questions} questions. (1=yes, 0=no)\")\n",
    "\n",
    "    # Adaptive mode\n",
    "    print(\"\"\"Adaptive mode:\n",
    "  0: Focus on questions you haven't seen (if all seen -> least seen; if none seen -> random)\n",
    "  1: Focus on questions you got wrong the most (if none seen -> random)\n",
    "  2: Random\n",
    "\"\"\")\n",
    "    adaptive_mode = prompt_choice(\"Enter 0, 1, or 2: \", {\"0\", \"1\", \"2\"})\n",
    "    adaptive_mode = int(adaptive_mode)\n",
    "\n",
    "    quit_requested = False\n",
    "    topic_key = None\n",
    "\n",
    "    if not full_test:\n",
    "        # Topic selection loop\n",
    "        while True:\n",
    "            print(\"Select a topic (or 0 to quit):\")\n",
    "            for k, v in TOPIC_MAP.items():\n",
    "                print(f\"  {k}: {v}\")\n",
    "            t = prompt_choice(\"Enter number (0..8): \", set(TOPIC_MAP.keys()) | {\"0\"})\n",
    "            if t == \"0\":\n",
    "                quit_requested = True\n",
    "                break\n",
    "            topic_key = t\n",
    "            break  # valid topic chosen\n",
    "\n",
    "    return full_test, number_of_questions, timed, adaptive_mode, quit_requested, topic_key\n",
    "\n",
    "# ---------------------------\n",
    "# Example student_history init (if not already loaded)\n",
    "# ---------------------------\n",
    "\n",
    "# If you already have a student_history loaded elsewhere, skip this block.\n",
    "if 'student_history' not in globals():\n",
    "    base = question_df[[\"Question\", \"Section\", \"Task\"]].copy()\n",
    "    # If the same Question appears in multiple tasks/sections and you want them separate, keep duplicates.\n",
    "    # Otherwise: base = base.drop_duplicates().reset_index(drop=True)\n",
    "    student_history = base.copy()\n",
    "    student_history[\"Number_attempts\"] = 0\n",
    "    student_history[\"Number_correct\"] = 0\n",
    "    # Optional: stable ids\n",
    "    student_history.insert(0, \"Question_ID\", range(1, len(student_history) + 1))\n",
    "import pandas as pd\n",
    "\n",
    "def get_topic_allocation(number_questions: int, percentage_by_task_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Integer allocation per task whose sum equals number_questions,\n",
    "    using largest-remainder (Hamilton) rounding on percentages.\n",
    "    \"\"\"\n",
    "    # raw (float) allocations\n",
    "    raw = {\n",
    "        task: percentage_by_task_dict[task] * number_questions / 100.0\n",
    "        for task in percentage_by_task_dict}\n",
    "    # floors\n",
    "    alloc = {task: int(v) for task, v in raw.items()}\n",
    "    used = sum(alloc.values())\n",
    "    remaining = number_questions - used\n",
    "    if remaining <= 0:\n",
    "        return alloc\n",
    "\n",
    "    # distribute by largest fractional remainders\n",
    "    remainders = sorted(\n",
    "        ((task, raw[task] - alloc[task]) for task in percentage_by_task_dict),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True)\n",
    "    for i in range(remaining):\n",
    "        alloc[remainders[i % len(remainders)][0]] += 1\n",
    "\n",
    "    return alloc\n",
    "\n",
    "\n",
    "def generate_test(full_test: bool, \n",
    "                  n_questions: int, \n",
    "                  timed: bool, \n",
    "                  adaptive_mode: int, \n",
    "                  want_quit: bool, \n",
    "                  topic_key: str,\n",
    "                  student_history: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns (practice_test_df, test_duration_seconds).\n",
    "    Uses student_history to prioritize selections for adaptive modes.\n",
    "    \"\"\"\n",
    "    # guard\n",
    "    required_q_cols = {\"Question\", \"Section\", \"Task\"}\n",
    "    required_h_cols = {\"Question\", \"Section\", \"Task\", \"Number_attempts\", \"Number_correct\"}\n",
    "    if not required_q_cols.issubset(set(question_df.columns)):\n",
    "        raise ValueError(\"question_df missing required columns\")\n",
    "    if not required_h_cols.issubset(set(student_history.columns)):\n",
    "        raise ValueError(\"student_history missing required columns\")\n",
    "\n",
    "    test_duration = n_questions * 79.411  # seconds (suggested)\n",
    "\n",
    "    if full_test:\n",
    "        question_bank = question_df.copy()\n",
    "        topic_question_counts = get_topic_allocation(n_questions, percentage_by_task_dict)\n",
    "    else:\n",
    "        topic = TOPIC_MAP[topic_key]\n",
    "        question_bank = question_df[question_df[\"Section\"] == topic].copy()\n",
    "\n",
    "        tasks_in_topic = list(task_by_section_dict.get(topic, []))\n",
    "        if len(tasks_in_topic) == 0:\n",
    "            # fallback: treat entire section as one bucket\n",
    "            topic_question_counts = {None: n_questions}\n",
    "        else:\n",
    "            base = n_questions // len(tasks_in_topic)\n",
    "            topic_question_counts = {t: base for t in tasks_in_topic}\n",
    "            # distribute remainder\n",
    "            rem = n_questions - sum(topic_question_counts.values())\n",
    "            for i in range(rem):\n",
    "                topic_question_counts[tasks_in_topic[i % len(tasks_in_topic)]] += 1\n",
    "\n",
    "    def select_by_history_for_task(task_name: str, k: int, mode: int) -> pd.DataFrame:\n",
    "        \"\"\"Pick up to k rows from question_bank for a given task using student_history priority.\"\"\"\n",
    "        if task_name is None:\n",
    "            hist_slice = student_history.copy()\n",
    "            bank_slice = question_bank.copy()\n",
    "        else:\n",
    "            hist_slice = student_history[student_history[\"Task\"] == task_name]\n",
    "            bank_slice = question_bank[question_bank[\"Task\"] == task_name]\n",
    "\n",
    "        if mode == 0:  # unseen / least seen first\n",
    "            hist_slice = hist_slice.sort_values(by=\"Number_attempts\", ascending=True)\n",
    "        elif mode == 1:  # most wrong (lowest score first)\n",
    "            # ensure score exists; if not, compute quickly\n",
    "            if \"score\" not in hist_slice.columns:\n",
    "                # (Number_correct + 1) / (Number_attempts*(1+eps) + eps)\n",
    "                eps = 1e-3\n",
    "                attempt_penalty = 1.0 + eps\n",
    "                num = hist_slice[\"Number_correct\"].astype(float) + 1.0\n",
    "                den = hist_slice[\"Number_attempts\"].astype(float) * attempt_penalty + eps\n",
    "                hist_slice = hist_slice.copy()\n",
    "                hist_slice[\"score\"] = num / den\n",
    "            hist_slice = hist_slice.sort_values(by=\"score\", ascending=True)\n",
    "        else:\n",
    "            # random: sample directly from bank\n",
    "            return bank_slice.sample(n=min(k, len(bank_slice)))\n",
    "\n",
    "        # Map prioritized questions to rows in bank\n",
    "        prioritized_qs = hist_slice[\"Question\"].tolist()\n",
    "        # keep order with Categorical sort, then take top k\n",
    "        if len(prioritized_qs) == 0:\n",
    "            return bank_slice.sample(n=min(k, len(bank_slice)))\n",
    "\n",
    "        ordered = (bank_slice.assign(_ord=pd.Categorical(\n",
    "            bank_slice[\"Question\"], \n",
    "            categories=prioritized_qs, ordered=True)).sort_values(\n",
    "            \"_ord\", na_position=\"last\").drop(columns=[\"_ord\"]))\n",
    "        return ordered.head(k)\n",
    "\n",
    "    practice_parts = []\n",
    "    if full_test:\n",
    "        for task, k in topic_question_counts.items():\n",
    "            if k <= 0:\n",
    "                continue\n",
    "            bank_slice = question_bank[question_bank[\"Task\"] == task]\n",
    "            if len(bank_slice) == 0:\n",
    "                continue\n",
    "            take = select_by_history_for_task(task, k, adaptive_mode)\n",
    "            practice_parts.append(take)\n",
    "    else:\n",
    "        # in-section selection across tasks per topic_question_counts\n",
    "        for task, k in topic_question_counts.items():\n",
    "            if k <= 0:\n",
    "                continue\n",
    "            if task is None:\n",
    "                bank_slice = question_bank\n",
    "            else:\n",
    "                bank_slice = question_bank[question_bank[\"Task\"] == task]\n",
    "            if len(bank_slice) == 0:\n",
    "                continue\n",
    "            take = select_by_history_for_task(task, k, adaptive_mode)\n",
    "            practice_parts.append(take)\n",
    "\n",
    "    practice_test = pd.concat(practice_parts, ignore_index=True) if practice_parts else pd.DataFrame(columns=list(question_df.columns))\n",
    "\n",
    "    # If we somehow undershot (e.g., not enough items in some buckets), top up randomly from remaining pool\n",
    "    if len(practice_test) < n_questions and len(question_bank) > len(practice_test):\n",
    "        remaining_needed = n_questions - len(practice_test)\n",
    "        remaining_pool = question_bank.merge(practice_test[[\"Question\"]], on=\"Question\", how=\"left\", indicator=True)\n",
    "        remaining_pool = remaining_pool[remaining_pool[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "        if len(remaining_pool) > 0:\n",
    "            practice_test = pd.concat([practice_test, remaining_pool.sample(n=min(remaining_needed, len(remaining_pool)), random_state=42)],ignore_index=True)\n",
    "\n",
    "    # final cap in case of over-selection\n",
    "    if len(practice_test) > n_questions:\n",
    "        practice_test = practice_test.sample(n=n_questions).reset_index(drop=True)\n",
    "    else:\n",
    "        practice_test = practice_test.reset_index(drop=True)\n",
    "\n",
    "    return practice_test, test_duration\n",
    "\n",
    "resolved = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Qiskit Practice Test!\n",
      "Starting interactive practice session...\n",
      "To begin, type 'None' (without quotes) at the prompt to create a new practice history.\n",
      "Or provide a path to load your previous history.\n",
      "\n",
      "Unable to load student history: [Errno 2] No such file or directory: ''\n",
      "Let's try again. Type 'None' to start fresh, or the path to your history file.\n",
      "Unable to load student history: [Errno 2] No such file or directory: ''\n",
      "Let's try again. Type 'None' to start fresh, or the path to your history file.\n",
      "Creating new student history (empty).\n",
      "Loaded Student History\n",
      "\n",
      "What would you like to do (type only the number)\n",
      "    1 Take a practice test\n",
      "    2 Save student history\n",
      "    3 Quit\n",
      "    4 View stats on my student history\n",
      "\n",
      "Invalid selection. Valid options: ['1', '2', '3', '4']\n",
      "Type '0' for an exam over all topics (proportions roughly match the test).\n",
      "Type '1' to select a topic.\n",
      "Invalid selection. Valid options: ['0', '1']\n",
      "Please enter 1/0 or y/n.\n",
      "Adaptive mode:\n",
      "  0: Focus on questions you haven't seen (if all seen -> least seen; if none seen -> random)\n",
      "  1: Focus on questions you got wrong the most (if none seen -> random)\n",
      "  2: Random\n",
      "\n",
      "Select a topic (or 0 to quit):\n",
      "  1: Section 1: Perform quantum operations\n",
      "  2: Section 2: Visualize quantum circuits, measurements, and states\n",
      "  3: Section 3: Create quantum circuits\n",
      "  4: Section 4: Run quantum circuits\n",
      "  5: Section 5: Use the sampler primitive\n",
      "  6: Section 6: Use the estimator primitive\n",
      "  7: Section 7: Retrieve and analyze the results of quantum circuits\n",
      "  8: Section 8: Operate with OpenQASM\n",
      "\n",
      "=== Practice Parameters ===\n",
      "Full test?         : False\n",
      "Num questions      : 1\n",
      "Timed              : True\n",
      "Adaptive mode      : 1\n",
      "Topic              : Section 2: Visualize quantum circuits, measurements, and states\n",
      "===========================\n",
      "\n",
      "You have 79 seconds — about 1 minutes.\n",
      "\n",
      "Question\n",
      "What does the filename parameter do in plot_gate_map?\n",
      "A: Saves the rendered image to the given path\n",
      "B: Specifies a backend configuration file\n",
      "C: Selects a matplotlib style\n",
      "D: Names the Figure object\n",
      "Time remaining = 49.3 seconds\n",
      "You entered an invalid answer choice. Question marked wrong.\n",
      "Incorrect. The correct answer is:\n",
      "Saves the rendered image to the given path\n",
      "Explanation:\n",
      "filename writes the visualization to disk.\n",
      "\n",
      "You got 0 of 1 correct in 30.1 seconds.\n",
      "=== Student History — Overall ===\n",
      "Questions ever attempted : 3 / 1023\n",
      "Total attempts           : 3\n",
      "Total correct            : 0\n",
      "Overall accuracy         : 0.00%\n",
      "\n",
      "=== By Section ===\n",
      "- Section 1: Perform quantum operations:  attempted 0/50 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "- Section 2: Visualize quantum circuits, measurements, and states:  attempted 3/213 |  attempts 3 | correct 0 |  acc 0.00%\n",
      "- Section 3: Create quantum circuits:  attempted 0/194 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "- Section 4: Run quantum circuits:  attempted 0/117 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "- Section 5: Use the sampler primitive:  attempted 0/67 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "- Section 6: Use the estimator primitive:  attempted 0/71 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "- Section 7: Retrieve and analyze the results of quantum circuits:  attempted 0/166 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "- Section 8: Operate with OpenQASM:  attempted 0/145 |  attempts 0 | correct 0 |  acc 0.00%\n",
      "Student History saved to: necessary_files/student_history_20251024_131540.pkl\n",
      "\n",
      "What would you like to do (type only the number)\n",
      "    1 Take a practice test\n",
      "    2 Save student history\n",
      "    3 Quit\n",
      "    4 View stats on my student history\n",
      "\n",
      "Invalid selection. Valid options: ['1', '2', '3', '4']\n",
      "Invalid selection. Valid options: ['1', '2', '3', '4']\n",
      "Student History saved to: necessary_files/student_history_20251024_131707.pkl\n",
      "\n",
      "What would you like to do (type only the number)\n",
      "    1 Take a practice test\n",
      "    2 Save student history\n",
      "    3 Quit\n",
      "    4 View stats on my student history\n",
      "\n",
      "Student History saved to: necessary_files/student_history_20251024_131714.pkl\n",
      "\n",
      "What would you like to do (type only the number)\n",
      "    1 Take a practice test\n",
      "    2 Save student history\n",
      "    3 Quit\n",
      "    4 View stats on my student history\n",
      "\n",
      "Invalid selection. Valid options: ['1', '2', '3', '4']\n",
      "Invalid selection. Valid options: ['1', '2', '3', '4']\n",
      "Invalid selection. Valid options: ['1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime  # for save_student_history timestamps\n",
    "\n",
    "# Initialize variables for student history loading\n",
    "resolved = False\n",
    "student_history = None\n",
    "\n",
    "# ------- Interactive Practice Session -------\n",
    "print(\"Welcome to the Qiskit Practice Test!\")\n",
    "print(\"Starting interactive practice session...\")\n",
    "print(\"To begin, type 'None' (without quotes) at the prompt to create a new practice history.\")\n",
    "print(\"Or provide a path to load your previous history.\\n\")\n",
    "\n",
    "while not resolved:\n",
    "    file_path = input(\"Provide file path for student history file. If you don't want to load a student history, type 'None': \")\n",
    "    student_history, resolved = load_student_history(file_path)\n",
    "    if not resolved:\n",
    "        print(\"Let's try again. Type 'None' to start fresh, or the path to your history file.\")\n",
    "\n",
    "if student_history is None:\n",
    "    # Initialize new student history\n",
    "    base = question_df[[\"Question\", \"Section\", \"Task\"]].copy()\n",
    "    student_history = base.copy()\n",
    "    student_history[\"Number_attempts\"] = 0\n",
    "    student_history[\"Number_correct\"] = 0\n",
    "    student_history.insert(0, \"Question_ID\", range(1, len(student_history) + 1))\n",
    "    print(\"Created new student history with\", len(student_history), \"questions.\")\n",
    "\n",
    "# ------- main loop -------\n",
    "quit_flag = False\n",
    "while not quit_flag:\n",
    "    quit_flag, practice_flag = main_menu(student_history)\n",
    "    if quit_flag:\n",
    "        print(\"\\nThanks for practicing! Your progress has been saved.\")\n",
    "        break\n",
    "    if practice_flag:\n",
    "        full_test, n_questions, timed, adaptive_mode, want_quit, topic_key = get_practice_params(question_df)\n",
    "        if want_quit:\n",
    "            continue\n",
    "\n",
    "        print(\"\\n=== Practice Parameters ===\")\n",
    "        print(f\"Full test?         : {full_test}\")\n",
    "        print(f\"Num questions      : {n_questions}\")\n",
    "        print(f\"Timed              : {timed}\")\n",
    "        print(f\"Adaptive mode      : {adaptive_mode}\")\n",
    "        print(f\"Topic              : {TOPIC_MAP.get(topic_key, 'All topics')}\")\n",
    "        print(\"===========================\\n\")\n",
    "\n",
    "        practice_test, duration = generate_test(\n",
    "            full_test,\n",
    "            n_questions, \n",
    "            timed, \n",
    "            adaptive_mode, \n",
    "            want_quit, \n",
    "            topic_key,\n",
    "            student_history\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        if timed:\n",
    "            print(f\"You have {duration:.0f} seconds — about {int(duration//60)} minutes.\")\n",
    "\n",
    "        correct_count = 0\n",
    "\n",
    "        for _, row in practice_test.iterrows():\n",
    "            print(\"\\nQuestion\")\n",
    "            print(row[\"Question\"])\n",
    "            print(\"A:\", row.get(\"Choice_A\", \"\"))\n",
    "            print(\"B:\", row.get(\"Choice_B\", \"\"))\n",
    "            print(\"C:\", row.get(\"Choice_C\", \"\"))\n",
    "            print(\"D:\", row.get(\"Choice_D\", \"\"))\n",
    "\n",
    "            answer = input(\"Select your choice: A, B, C, or D \").strip().upper()[:1]\n",
    "\n",
    "            # update attempts\n",
    "            mask = (student_history[\"Question\"] == row[\"Question\"])\n",
    "            student_history.loc[mask, \"Number_attempts\"] = student_history.loc[mask, \"Number_attempts\"] + 1\n",
    "\n",
    "            # time check\n",
    "            current_duration = time.time() - start_time\n",
    "            if timed:\n",
    "                remaining = max(0, duration - current_duration)\n",
    "                print(f\"Time remaining = {remaining:.1f} seconds\")\n",
    "                if current_duration > duration:\n",
    "                    print(\"Out of time.\")\n",
    "                    break\n",
    "\n",
    "            # evaluate answer\n",
    "            is_valid = answer in {\"A\", \"B\", \"C\", \"D\"}\n",
    "            correct_field = row.get(\"Correct_Answer\", None)\n",
    "\n",
    "            if not is_valid:\n",
    "                print(\"You entered an invalid answer choice. Question marked wrong.\")\n",
    "                is_correct = False\n",
    "            else:\n",
    "                # If Correct_Answer is a letter, compare letters; otherwise compare the text of the chosen option.\n",
    "                if isinstance(correct_field, str) and correct_field in {\"A\", \"B\", \"C\", \"D\"}:\n",
    "                    is_correct = (answer == correct_field)\n",
    "                else:\n",
    "                    is_correct = (row.get(f\"Choice_{answer}\") == correct_field)\n",
    "\n",
    "            if is_correct:\n",
    "                print(\"Correct!\")\n",
    "                correct_count += 1\n",
    "                student_history.loc[mask, \"Number_correct\"] = student_history.loc[mask, \"Number_correct\"] + 1\n",
    "            else:\n",
    "                print(\"Incorrect. The correct answer is:\")\n",
    "                if isinstance(correct_field, str) and correct_field in {\"A\", \"B\", \"C\", \"D\"}:\n",
    "                    print(correct_field)\n",
    "                else:\n",
    "                    print(correct_field)\n",
    "\n",
    "            # explanation (if present)\n",
    "            expl = row.get(\"Explanation\", None)\n",
    "            if expl is not None:\n",
    "                print(\"Explanation:\")\n",
    "                print(expl)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nYou got {correct_count} of {n_questions} correct in {total_time:.1f} seconds.\")\n",
    "\n",
    "        update_scores(student_history)\n",
    "        print_stats(student_history)\n",
    "        save_student_history(student_history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8426090,
     "sourceId": 13301240,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 266445321,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "qiskit-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
